# NetGym Service

> **âš¾ Baseball Player Management & AI Bio Generation**

**NetGym Service** is a comprehensive backend API built with **FastAPI**, following **Clean Architecture** principles and **Domain-Driven Design (DDD)**. It manages baseball players, gym activities, and leverages **Generative AI** to create dynamic player biographies.

The system uses **PostgreSQL** as its database engine and supports **Multi-tenancy**.

---

## ğŸš€ Key Features

*   **RESTful API**: Built with FastAPI for high performance.
*   **AI Integration**: **OpenAI** integration for generating creative player biographies.
*   **Clean Architecture**: Separation of concerns into Domain, Application, and Infrastructure layers.
*   **Multi-tenancy**: Robust support for multiple tenants with isolated data.
*   **Database**: Native support for **PostgreSQL** with **SQLAlchemy** & **SQLModel**.
*   **Authentication**: JWT-based authentication with role management.
*   **Validation**: Robust data validation using Pydantic v2.
*   **Containerization**: Docker and Docker Compose support for easy deployment.
*   **Testing**: Comprehensive test suite with pytest.

---

## ğŸ› ï¸ Technology Stack

*   **Language**: Python 3.13
*   **Framework**: FastAPI
*   **AI/LLM**: OpenAI API
*   **ORM**: SQLAlchemy & SQLModel
*   **Migrations**: Alembic
*   **Dependency Management**: Pipenv
*   **Database**: PostgreSQL
*   **Testing**: Pytest, Pytest-cov
*   **Code Quality**: Black, Isort, Flake8, Pylint

---

## ğŸ—ï¸ Project Structure

The project follows a strict **Hexagonal Architecture** (Ports & Adapters) structure within the `src/` directory:

```text
src/
â”œâ”€â”€ application/                # Application Layer (Use Cases, DTOs)
â”‚   â”œâ”€â”€ dtos/                   # Data Transfer Objects
â”‚   â”œâ”€â”€ services/               # Application Services
â”‚   â””â”€â”€ use_cases/              # Business Logic Execution
â”‚
â”œâ”€â”€ domain/                     # Domain Layer (Enterprise Logic)
â”‚   â”œâ”€â”€ entities/               # Domain Entities
â”‚   â”œâ”€â”€ factories/              # Object Creation Strategies
â”‚   â”œâ”€â”€ ports/                  # Interfaces (Repositories, Services)
â”‚   â”‚   â”œâ”€â”€ repositories/       # Repository Interfaces
â”‚   â”‚   â””â”€â”€ services/           # Service Interfaces
â”‚   â”œâ”€â”€ domain_services/        # Domain-specific logic
â”‚   â””â”€â”€ value_objects/          # Immutable Domain Objects
â”‚
â”œâ”€â”€ infrastructure/             # Infrastructure Layer (External Details)
â”‚   â”œâ”€â”€ config/                 # Settings & Database Config
â”‚   â”œâ”€â”€ controllers/            # API Routes (FastAPI)
â”‚   â”œâ”€â”€ models/                 # ORM Models (SQLAlchemy)
â”‚   â”œâ”€â”€ repositories/           # Data Access Implementations
â”‚   â””â”€â”€ migrations/             # Alembic Scripts
â”‚
â””â”€â”€ shared/                     # Shared Utilities & Constants
    â”œâ”€â”€ exceptions/             # Custom Exceptions
    â””â”€â”€ utils/                  # Helper Functions
```

---

## âš™ï¸ Installation & Setup

### 1. Prerequisites

*   Python 3.13+
*   Pipenv (`pip install --user pipenv`)
*   Docker & Docker Compose (optional, for database)
*   PostgreSQL (if not using Docker)

### 2. Clone and Install

```bash
git clone [REPOSITORY_URL]
cd netgym-service

# Install dependencies
pipenv install --dev
pipenv shell
```

### 3. Environment Configuration

Copy the example environment file and configure it:

```bash
cp .env.example .env
```

> **Note**: Update database credentials (`DB_USER`, `DB_PASS`, etc.) and **OpenAI API Key** (`OPENAI_API_KEY`) in `.env`.

---

## ğŸ³ Docker Setup (Database)

We provide a Docker Compose file to easily spin up a database instance.

```bash
docker-compose -f docker-compose.yml up -d
```

*This command starts a container with PostgreSQL.*

---

## ğŸ“¦ Database Migrations (Alembic)

We use Alembic to manage database schema updates, supporting multi-tenancy.

### 1. Create a New Migration

Generates a new migration file based on model changes.

```bash
pipenv run makemigration "description_of_change"

# OR manually:
alembic -c src/infrastructure/config/migrations/alembic.ini revision --autogenerate -m "description_of_change"
```

### 2. Apply Migrations (Upgrade)

Updates the database to the latest version.

```bash
alembic -c src/infrastructure/config/migrations/alembic.ini upgrade head
```

### 3. Revert Migrations (Downgrade)

Reverts the last migration.

```bash
alembic -c src/infrastructure/config/migrations/alembic.ini downgrade -1
```

### 4. Multi-Tenant Migrations

To manage migrations across all tenants:

```bash
# Apply to all tenants
pipenv run migrate-all

# Downgrade all tenants
pipenv run downgrade-all
```

---

## â–¶ï¸ Running the Application

### Development Mode

Start the server with hot reload:

```bash
pipenv run start

# OR manually:
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

The API will be available at:
-   **API**: http://localhost:8000
-   **Swagger Docs**: http://localhost:8000/docs
-   **ReDoc**: http://localhost:8000/redoc

### Docker

To run the full application stack via Docker:

```bash
docker-compose up --build -d
```

---

## ğŸ§ª Testing & Code Quality

Run the test suite and quality checks using the scripts defined in `Pipfile`:

### Run Tests

```bash
# Run all tests
pipenv run test

# Run with coverage report
pipenv run coverage
```

### Code Quality

```bash
# Format code (Black & Isort)
pipenv run format

# Run linters (Flake8 & Pylint)
pipenv run lint
```

---

## ğŸ”’ Security

```bash
# Run security checks
pipenv run bandit -r src/

# Check for vulnerable dependencies
pipenv run safety check
```

---

## ğŸ¤ Contributing

1.  Create a feature branch (`git checkout -b feature/amazing-feature`)
2.  Make your changes following the architecture patterns
3.  Write tests for your changes
4.  Run quality checks (`pipenv run format && pipenv run lint && pipenv run test`)
5.  Commit your changes (`git commit -m 'Add amazing feature'`)
6.  Push to the branch (`git push origin feature/amazing-feature`)
7.  Open a Pull Request

---

## ğŸ‘¥ Authors

*   **NetGym Team**
